# SPARK IMAGE BUILD
x-spark-build-config: &build-config
  context: .
  dockerfile: dockerfiles/standalone_spark_cluster/spark.Dockerfile

# COMMON SETTINGS FOR SPARK SERVICES
x-spark-common: &spark-common
  #image: bitnami/spark:3.5.1
  image: standalone_spark_cluster
  env_file:
    - .env.spark
    - .env
#  extra_hosts:
#    - "host.docker.internal:172.17.0.1"
#    - "host.docker.internal:172.18.0.3"
#    - "host.docker.internal:host-gateway"
  volumes:
    - ./libs/postgresql-42.7.4.jar:/opt/spark/jars/postgresql-42.7.4.jar
    - ./logs:/opt/spark/spark-events
    - ./src/input:/opt/spark/data
    - .:/opt/spark/apps
  networks:
    - spark-network


services:

  standalone_spark_cluster:
    image: standalone_spark_cluster
    build: *build-config

  spark-master:
    <<: *spark-common
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    entrypoint: ['/opt/spark/entrypoint.sh', 'master']
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 5s
      timeout: 3s
      retries: 3
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no

  spark-worker:
    <<: *spark-common
    container_name: spark-worker
    entrypoint: ['/opt/spark/entrypoint.sh', 'worker']
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 1
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no

networks:
  spark-network:
    external: true
    #driver: bridge


# JUPYTER FOR EASIER SETUP IN IDE
#  jupyter:
#    image: jupyter/pyspark-notebook:python-3.11
#    container_name: jupyter-notebook
#    ports:
#      - "8888:8888"
#      - "4040:4040"
#    networks:
#      - spark-network
#    environment:
#      - SPARK_OPTS="--master=spark://spark-master:7077"
#    volumes:
#      - ./src/input:/home/jovyan/work

#volumes:
#  spark-logs: